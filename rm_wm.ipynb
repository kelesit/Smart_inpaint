{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动化去水印(智能抠图!)\n",
    "\n",
    "Step 1:\n",
    "通过BirefNet得到商品主体蒙版\n",
    "\n",
    "step2:\n",
    "将主体部分inpaint掉，防止干扰 (存疑，或许不需要，也有可能会导致inpaint效果不佳)\n",
    "\n",
    "Step 3:\n",
    "OCR识别每组文字，得到每组文字的边界框\n",
    "\n",
    "Step 4:\n",
    "每组文字的边界框和中心点作为segment anything的输入，得到每组文字的蒙版\n",
    "\n",
    "Step 5:\n",
    "将文字蒙版合并，inpaint，得到无文字的干净背景\n",
    "\n",
    "Step 6:\n",
    "将商品主体蒙版和无文字的干净背景融合，得到最终结果\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# import psutil\n",
    "# import os\n",
    "\n",
    "# def clear_all_memory():\n",
    "#     \"\"\"清理内存函数\"\"\"\n",
    "#     # 清理 CUDA 缓存\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(f\"GPU内存已清空\")\n",
    "#         print(f\"当前GPU内存占用：{torch.cuda.memory_allocated()/1024**2:.2f} MB\")\n",
    "    \n",
    "#     # 清理 CPU 缓存\n",
    "#     gc.collect()\n",
    "    \n",
    "#     # 获取进程信息\n",
    "#     process = psutil.Process(os.getpid())\n",
    "#     print(f\"CPU内存占用：{process.memory_info().rss/1024/1024:.2f} MB\")\n",
    "#     print(\"内存清理完成\")\n",
    "\n",
    "# clear_all_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_dir = '/root/rm_water_mark/test_imgs'\n",
    "img_name = '11'\n",
    "img_path = f'/root/rm_water_mark/test_imgs/{img_name}.jpg'\n",
    "product_mask_path = f'/root/rm_water_mark/test_imgs/{img_name}_mask.jpg'\n",
    "pic_no_prod_path = f'/root/rm_water_mark/test_imgs/{img_name}_no_prod.jpg'\n",
    "water_mark_mask_path = f'/root/rm_water_mark/test_imgs/{img_name}_water_mark_mask.jpg'\n",
    "pic_clean_bg_path = f'/root/rm_water_mark/test_imgs/{img_name}_clean_bg.jpg'\n",
    "final_img_path = f'/root/rm_water_mark/test_imgs/{img_name}_rm.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 读取原图\n",
    "# original_image = Image.open(img_path)\n",
    "original_image = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过rmbg得到原图+主体蒙版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import AutoModelForImageSegmentation\n",
    "\n",
    "MODEL_DIR = '/root/autodl-tmp/RMBG-2.0'\n",
    "\n",
    "input_image_size = (1024, 1024)\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize(input_image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# image = cv2.imread(image_path)\n",
    "# mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_images, original_size):\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_images)[-1].sigmoid().cpu()\n",
    "    pred = preds[0].squeeze()\n",
    "    pred_pil = transforms.ToPILImage()(pred)\n",
    "    mask = pred_pil.resize(original_size)\n",
    "    return mask\n",
    "\n",
    "def run_inference(image: Image):\n",
    "    \"\"\"\n",
    "    result_image = run_inference(image)\n",
    "    \"\"\"\n",
    "    # image\n",
    "    original_size = image.size\n",
    "\n",
    "    # load model\n",
    "    model = AutoModelForImageSegmentation.from_pretrained(MODEL_DIR, trust_remote_code=True)\n",
    "    torch.set_float32_matmul_precision(['high', 'highest'][0])\n",
    "    model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "    # process img\n",
    "    input_images = transform_image(image).unsqueeze(0).to('cuda')\n",
    "    # predict\n",
    "    mask = predict(model, input_images, original_size)\n",
    "    # # post process\n",
    "    # image.putalpha(mask)\n",
    "    # # 创建白色背景\n",
    "    # white_background = Image.new(\"RGBA\", original_size, (255, 255, 255, 255))\n",
    "    # # 将透明图像与白底合成\n",
    "    # composite = Image.alpha_composite(white_background, image)\n",
    "    # final_img = composite.convert(\"RGB\")\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mask = run_inference(Image.fromarray(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)))\n",
    "product_mask.save(product_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将product_mask转换为cv2格式\n",
    "product_mask = np.array(product_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Inpaint anything 把商品主体(蒙版部分)消除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/root/Inpaint-Anything-main')\n",
    "sys.path.insert(0, '/root/Inpaint-Anything-main/..')\n",
    "\n",
    "from lama_inpaint import load_inpaint_model, inpaint_img_with_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INPAINT_ANYTHING_DIR = Path(r'/root/Inpaint-Anything-main')\n",
    "LAMA_CONFIG = INPAINT_ANYTHING_DIR.joinpath('lama', 'configs', 'prediction', 'default.yaml')\n",
    "LAMA_CKPT = '/root/autodl-tmp/pretrained_models/big-lama'\n",
    "\n",
    "lama_predictor, lama_predict_config = load_inpaint_model(LAMA_CONFIG, LAMA_CKPT)\n",
    "\n",
    "cv_kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "#先对蒙版进行膨胀操作\n",
    "mask = cv2.dilate(product_mask, cv_kernel, iterations=3)\n",
    "\n",
    "def inpaint_img(image_array, mask):\n",
    "    img_inpainted = inpaint_img_with_model(img=image_array,\n",
    "                                           mask=mask,\n",
    "                                           model=lama_predictor,\n",
    "                                           predict_config=lama_predict_config)\n",
    "    return img_inpainted\n",
    "\n",
    "image_array = np.array(original_image)\n",
    "mask_array = np.array(mask)\n",
    "img_inpainted = inpaint_img(image_array, mask_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(pic_no_prod_path, img_inpainted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ocr识别文字组\n",
    "\n",
    "没有用原先的pytesseract，使用了 paddle ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/26 19:28:57] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=True, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/autodl-tmp/paddleocr/det/ch_ppocr_server_v2.0_det_infer/', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/autodl-tmp/paddleocr/rec/ch_ppocr_server_v2.0_rec_infer/', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/root/miniconda3/envs/sam/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/autodl-tmp/paddleocr/cls/ch_ppocr_mobile_v2.0_cls_infer/', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/12/26 19:28:57] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2024/12/26 19:28:58] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2024/12/26 19:28:59] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2024/12/26 19:29:00] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.08710026741027832\n",
      "[2024/12/26 19:29:00] ppocr DEBUG: cls num  : 2, elapsed : 0.021065473556518555\n",
      "[2024/12/26 19:29:00] ppocr DEBUG: rec_res num  : 2, elapsed : 0.044973134994506836\n",
      "0\n",
      "[[[768.0, 440.0], [835.0, 440.0], [835.0, 509.0], [768.0, 509.0]], ('光', 0.998345136642456)]\n",
      "[[[125.0, 551.0], [842.0, 548.0], [842.0, 588.0], [125.0, 591.0]], ('A需担心', 0.6453725695610046)]\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "ocr = PaddleOCR(\n",
    "    use_angle_cls=True, \n",
    "    lang='ch',\n",
    "    det_model_dir='/root/autodl-tmp/paddleocr/det/ch_ppocr_server_v2.0_det_infer/',\n",
    "    rec_model_dir='/root/autodl-tmp/paddleocr/rec/ch_ppocr_server_v2.0_rec_infer/',\n",
    "    cls_model_dir='/root/autodl-tmp/paddleocr/cls/ch_ppocr_mobile_v2.0_cls_infer/',\n",
    "    ) # need to run only once to download and load model into memory\n",
    "\n",
    "# img_path = '/root/rm_water_mark/imgs/image2_inpainted.jpg'\n",
    "# 注意 ocr.ocr()如果传入的是ndarray,结果需要去result[0]获取\n",
    "result = ocr.ocr(img_inpainted, cls=True)    # image path / ndarray\n",
    "if len(result) == 0:\n",
    "    print('No text detected!')\n",
    "    pass\n",
    "\n",
    "for idx in range(len(result)):\n",
    "    print(idx)\n",
    "    res = result[idx]\n",
    "    for line in res:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = [line[0] for line in result]\n",
    "boxes = [line[0] for line in result[0]]\n",
    "# 计算中心点\n",
    "def get_center(box):\n",
    "    x = (box[0][0] + box[2][0]) / 2\n",
    "    y = (box[0][1] + box[2][1]) / 2\n",
    "    return [x, y]\n",
    "\n",
    "# 增加中心点作为box的第五个点\n",
    "def add_center(boxes):\n",
    "    for box in boxes:\n",
    "        center = get_center(box)\n",
    "        box.append(center)\n",
    "    return boxes\n",
    "\n",
    "# boxes = add_center(boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用segment anything 得到文字蒙版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAM_MODEL_TYPE = 'vit_h'\n",
    "SAM_CKPT = '/root/autodl-tmp/pretrained_models/sam_vit_h_4b8939.pth'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "def initialize_sam(checkpoint_path, model_type=\"vit_h\", device=\"cuda\"):\n",
    "    \"\"\" 初始化 SAM 模型 \"\"\"\n",
    "    sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "    sam.to(device)\n",
    "    predictor = SamPredictor(sam)\n",
    "    return predictor\n",
    "\n",
    "def get_mask_from_points(predictor, image, points):\n",
    "    \"\"\"\n",
    "    从点集获取mask\n",
    "    Args:\n",
    "        predictor: SAM 预测器\n",
    "        image:输入图像(nparray, RGB)\n",
    "        points: 点的坐标列表 [x1, y1], [x2, y2], ...\n",
    "    Returns:\n",
    "        masks: 生成的蒙版\n",
    "        scores: 蒙版的置信度\n",
    "    \"\"\"\n",
    "    predictor.set_image(image)\n",
    "    input_points = np.array(points)\n",
    "    point_labels = np.ones(len(points))\n",
    "\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords = input_points,\n",
    "        point_labels = point_labels,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "\n",
    "    return masks, scores\n",
    "\n",
    "def process_mask(mask, dilate_kernel_size=5, num_iterations=2):\n",
    "    \"\"\" 膨胀蒙版 \"\"\"\n",
    "    # 将bool转为uint8\n",
    "    mask_uint8 = mask.astype(np.uint8) * 255\n",
    "\n",
    "    # 创建膨胀核\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilate_kernel_size, dilate_kernel_size))\n",
    "    # 膨胀\n",
    "    dilated_mask = cv2.dilate(mask_uint8, kernel, iterations=num_iterations)\n",
    "    blurred_mask = cv2.GaussianBlur(dilated_mask, (5, 5), 0)\n",
    "    # 转回布尔类型\n",
    "    final_mask = blurred_mask > 127\n",
    "\n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取模型文件/root/autodl-tmp/pretrained_models/sam_vit_h_4b8939.pth\n"
     ]
    }
   ],
   "source": [
    "predictor = initialize_sam(SAM_CKPT, SAM_MODEL_TYPE, DEVICE)\n",
    "\n",
    "samed_masks = []\n",
    "for points in boxes:\n",
    "    masks, scores = get_mask_from_points(predictor, img_inpainted, points)\n",
    "    \n",
    "    best_mask_index = np.argmax(scores)\n",
    "    best_mask = masks[best_mask_index]\n",
    "\n",
    "    processed_mask = process_mask(\n",
    "        best_mask,\n",
    "        dilate_kernel_size=5,\n",
    "        num_iterations=2\n",
    "    )\n",
    "    samed_masks.append(processed_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将boxes转换为box_masks\n",
    "def get_box_mask(box, image_shape):\n",
    "    mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [np.array(box, dtype=np.int32)], 1)\n",
    "    # 膨胀处理\n",
    "    cv_kernel = np.ones((5, 5), dtype=np.uint8)\n",
    "    mask = cv2.dilate(mask, cv_kernel, iterations=3)\n",
    "    return mask\n",
    "\n",
    "def get_boxes_mask(boxes, image_shape):\n",
    "    masks = []\n",
    "    for box in boxes:\n",
    "        mask = get_box_mask(box, image_shape)\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "boxes_mask = get_boxes_mask(boxes, img_inpainted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6560\n",
      "38726\n",
      "------------------\n",
      "697195\n",
      "696049\n"
     ]
    }
   ],
   "source": [
    "for box_mask in boxes_mask:\n",
    "    print(np.sum(box_mask))\n",
    "print('------------------')\n",
    "for samed_mask in samed_masks:\n",
    "    print(np.sum(samed_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def get_final_masks(boxes_mask, \n",
    "                    samed_masks,\n",
    "                    area_ratio_threshold: float = 2.0,\n",
    "                    iou_threshold: float = 0.3,      # 用于判断两个SAM框是否相似\n",
    "                    distance_threshold: float = 50    # 用于判断两个框是否足够接近\n",
    "                    ) -> List[List[List[float]]]:\n",
    "    \"\"\"\n",
    "    根据原始文本框和SAM处理后的框来决定最终使用的框\n",
    "    \n",
    "    Args:\n",
    "        boxes_mask: 由文字box掩码组成的列表\n",
    "        samed_masks: SAM处理后的掩码列表\n",
    "        area_ratio_threshold: SAM框与原始框面积比的阈值，默认2.0\n",
    "        iou_threshold: 判断两个SAM框相似度的IOU阈值\n",
    "        distance_threshold: 判断两个框是否接近的距离阈值（像素）\n",
    "        \n",
    "    Returns:\n",
    "        最终确定的框列表\n",
    "    \"\"\"\n",
    "    final_masks = []\n",
    "    n = len(boxes_mask)\n",
    "    \n",
    "    # 首先检查相邻的SAM框是否构成文本框\n",
    "    text_block_groups = []  # 存储可能属于同一个文本框的mask组\n",
    "    processed = set()       # 记录已经处理过的mask索引\n",
    "    \n",
    "    def calculate_box_distance(mask1, mask2):\n",
    "        \"\"\"计算两个掩码的中心点距离\"\"\"\n",
    "        y1, x1 = np.mean(np.where(mask1), axis=1)\n",
    "        y2, x2 = np.mean(np.where(mask2), axis=1)\n",
    "        return np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "    \n",
    "    def calculate_iou(mask1, mask2):\n",
    "        \"\"\"计算两个掩码的IOU\"\"\"\n",
    "        intersection = np.sum(mask1 & mask2)\n",
    "        union = np.sum(mask1 | mask2)\n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    # 寻找可能属于同一文本框的mask组\n",
    "    for i in range(n):\n",
    "        if i in processed:\n",
    "            continue\n",
    "            \n",
    "        current_group = [i]\n",
    "        for j in range(i+1, n):\n",
    "            if j in processed:\n",
    "                continue\n",
    "                \n",
    "            # 计算两个SAM掩码的相似度和距离\n",
    "            iou = calculate_iou(samed_masks[i], samed_masks[j])\n",
    "            distance = calculate_box_distance(samed_masks[i], samed_masks[j])\n",
    "            \n",
    "            # 如果两个掩码足够相似且距离适中，认为它们可能属于同一个文本框\n",
    "            if iou > iou_threshold and distance < distance_threshold:\n",
    "                current_group.append(j)\n",
    "                processed.add(j)\n",
    "                \n",
    "        if len(current_group) > 1:  # 如果找到多个相关的掩码\n",
    "            text_block_groups.append(current_group)\n",
    "        processed.add(i)\n",
    "\n",
    "\n",
    "    ungroup_index = [] # 用于记录不属于任何文本块组的mask索引\n",
    "    # 根据text_block_groups制作grouping_masks 然后使用面积比逻辑\n",
    "    for group in text_block_groups:\n",
    "        grouping_mask = []\n",
    "        idx_list = []\n",
    "        for idx in group:\n",
    "            grouping_mask.append(boxes_mask[idx])\n",
    "            idx_list.append(idx)\n",
    "        group_area = np.sum(grouping_mask)\n",
    "        samed_area = np.sum(samed_masks[idx_list[0]])\n",
    "        area_ratio = samed_area / group_area if group_area > 0 else float('inf')\n",
    "\n",
    "        if area_ratio > area_ratio_threshold:\n",
    "            ungroup_index.extend(idx_list)\n",
    "\n",
    "    \n",
    "    # 处理每个mask\n",
    "    for i in range(n):\n",
    "        if i in ungroup_index:  \n",
    "            final_masks.append(boxes_mask[i])\n",
    "            continue\n",
    "\n",
    "        # 检查当前mask是否属于某个文本块组\n",
    "        is_in_text_block = False\n",
    "        for group in text_block_groups:\n",
    "            if i in group:\n",
    "                is_in_text_block = True\n",
    "                # 如果是组内第一个mask，合并该组所有mask\n",
    "                if i == group[0]:\n",
    "                    merged_mask = np.zeros_like(samed_masks[i], dtype=bool)\n",
    "                    for idx in group:\n",
    "                        merged_mask |= samed_masks[idx]\n",
    "                    final_masks.append(merged_mask)\n",
    "                break\n",
    "        \n",
    "        # 如果不属于任何文本块组，使用原有的面积比逻辑\n",
    "        if not is_in_text_block:\n",
    "            orig_area = np.sum(boxes_mask[i])\n",
    "            samed_area = np.sum(samed_masks[i])\n",
    "            area_ratio = samed_area / orig_area if orig_area > 0 else float('inf')\n",
    "            \n",
    "            if area_ratio > area_ratio_threshold:\n",
    "                final_masks.append(boxes_mask[i])\n",
    "            else:\n",
    "                final_masks.append(samed_masks[i])\n",
    "    \n",
    "    return final_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "\n",
    "# def get_final_masks(boxes_mask, \n",
    "#                     samed_masks,\n",
    "#                     area_ratio_threshold: float = 2.0,\n",
    "#                     iou_threshold: float = 0.3,      # 用于判断两个SAM框是否相似\n",
    "#                     distance_threshold: float = 50    # 用于判断两个框是否足够接近\n",
    "#                     ) -> List[List[List[float]]]:\n",
    "#     \"\"\"\n",
    "#     根据原始文本框和SAM处理后的框来决定最终使用的框\n",
    "    \n",
    "#     Args:\n",
    "#         boxes_mask: 由文字box掩码组成的列表\n",
    "#         samed_masks: SAM处理后的掩码列表\n",
    "#         area_ratio_threshold: SAM框与原始框面积比的阈值，默认2.0\n",
    "#         iou_threshold: 判断两个SAM框相似度的IOU阈值\n",
    "#         distance_threshold: 判断两个框是否接近的距离阈值（像素）\n",
    "        \n",
    "#     Returns:\n",
    "#         最终确定的框列表\n",
    "#     \"\"\"\n",
    "#     final_masks = []\n",
    "#     n = len(boxes_mask)\n",
    "    \n",
    "#     # 首先检查相邻的SAM框是否构成文本框\n",
    "#     text_block_groups = []  # 存储可能属于同一个文本框的mask组\n",
    "#     processed = set()       # 记录已经处理过的mask索引\n",
    "    \n",
    "#     def calculate_box_distance(mask1, mask2):\n",
    "#         \"\"\"计算两个掩码的中心点距离\"\"\"\n",
    "#         y1, x1 = np.mean(np.where(mask1), axis=1)\n",
    "#         y2, x2 = np.mean(np.where(mask2), axis=1)\n",
    "#         return np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "    \n",
    "#     def calculate_iou(mask1, mask2):\n",
    "#         \"\"\"计算两个掩码的IOU\"\"\"\n",
    "#         intersection = np.sum(mask1 & mask2)\n",
    "#         union = np.sum(mask1 | mask2)\n",
    "#         return intersection / union if union > 0 else 0\n",
    "    \n",
    "#     # 寻找可能属于同一文本框的mask组\n",
    "#     for i in range(n):\n",
    "#         if i in processed:\n",
    "#             continue\n",
    "            \n",
    "#         current_group = [i]\n",
    "#         for j in range(i+1, n):\n",
    "#             if j in processed:\n",
    "#                 continue\n",
    "                \n",
    "#             # 计算两个SAM掩码的相似度和距离\n",
    "#             iou = calculate_iou(samed_masks[i], samed_masks[j])\n",
    "#             distance = calculate_box_distance(samed_masks[i], samed_masks[j])\n",
    "            \n",
    "#             # 如果两个掩码足够相似且距离适中，认为它们可能属于同一个文本框\n",
    "#             if iou > iou_threshold and distance < distance_threshold:\n",
    "#                 current_group.append(j)\n",
    "#                 processed.add(j)\n",
    "                \n",
    "#         if len(current_group) > 1:  # 如果找到多个相关的掩码\n",
    "#             text_block_groups.append(current_group)\n",
    "#         processed.add(i)\n",
    "    \n",
    "#     # 处理每个mask\n",
    "#     for i in range(n):\n",
    "#         # 检查当前mask是否属于某个文本块组\n",
    "#         is_in_text_block = False\n",
    "#         for group in text_block_groups:\n",
    "#             if i in group:\n",
    "#                 is_in_text_block = True\n",
    "#                 # 如果是组内第一个mask，合并该组所有mask\n",
    "#                 if i == group[0]:\n",
    "#                     merged_mask = np.zeros_like(samed_masks[i], dtype=bool)\n",
    "#                     for idx in group:\n",
    "#                         merged_mask |= samed_masks[idx]\n",
    "#                     final_masks.append(merged_mask)\n",
    "#                 break\n",
    "        \n",
    "#         # 如果不属于任何文本块组，使用原有的面积比逻辑\n",
    "#         if not is_in_text_block:\n",
    "#             orig_area = np.sum(boxes_mask[i])\n",
    "#             samed_area = np.sum(samed_masks[i])\n",
    "#             area_ratio = samed_area / orig_area if orig_area > 0 else float('inf')\n",
    "            \n",
    "#             if area_ratio > area_ratio_threshold:\n",
    "#                 final_masks.append(boxes_mask[i])\n",
    "#             else:\n",
    "#                 final_masks.append(samed_masks[i])\n",
    "    \n",
    "#     return final_masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "\n",
    "# def get_final_masks(boxes_mask, \n",
    "#                    samed_masks,\n",
    "#                    area_ratio_threshold: float = 2.0) -> List[List[List[float]]]:\n",
    "#     \"\"\"\n",
    "#     根据原始文本框和SAM处理后的框来决定最终使用的框\n",
    "    \n",
    "#     Args:\n",
    "#         boxes: 由文字box组成的列表，每个文字box内包含由4个坐标点组成的列表，每个坐标点为[x, y]\n",
    "#         samed_boxes: 同上，为SAM处理后的框\n",
    "#         area_ratio_threshold: SAM框与原始框面积比的阈值，默认2.0\n",
    "        \n",
    "#     Returns:\n",
    "#         最终确定的框列表\n",
    "#     \"\"\"\n",
    "#     final_masks = []\n",
    "    \n",
    "#     for box_mask, samed_mask in zip(boxes_mask, samed_masks):\n",
    "#         # 计算面积\n",
    "#         # 计算原始框和SAM框的面积\n",
    "#         orig_area = np.sum(box_mask)\n",
    "#         samed_area = np.sum(samed_mask)\n",
    "#         # 计算面积比\n",
    "#         area_ratio = samed_area / orig_area if orig_area > 0 else float('inf')\n",
    "        \n",
    "#         # 如果SAM框面积过大，使用原始框\n",
    "#         if area_ratio > area_ratio_threshold:\n",
    "#             final_masks.append(box_mask)\n",
    "#         else:\n",
    "#             final_masks.append(samed_mask)\n",
    "    \n",
    "#     return final_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('boxes_mask.npy', boxes_mask)\n",
    "np.save('samed_masks.npy', samed_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_masks = get_final_masks(boxes_mask, samed_masks, area_ratio_threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_mask = np.zeros_like(final_masks[0], dtype=bool)\n",
    "for i, mask in enumerate(final_masks):\n",
    "    combined_mask = combined_mask | mask\n",
    "\n",
    "    # # 同时保存单独的蒙版\n",
    "    # individual_mask = (mask * 255).astype(np.uint8)\n",
    "    # cv2.imwrite(f\"mask_{i+1}.png\", individual_mask)\n",
    "\n",
    "# 保存组合蒙版\n",
    "combined_mask = (combined_mask * 255).astype(np.uint8)\n",
    "cv2.imwrite(water_mark_mask_path, combined_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 combined 蒙版进行inpaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INPAINT_ANYTHING_DIR = Path(r'/root/Inpaint-Anything-main')\n",
    "LAMA_CONFIG = INPAINT_ANYTHING_DIR.joinpath('lama', 'configs', 'prediction', 'default.yaml')\n",
    "LAMA_CKPT = '/root/autodl-tmp/pretrained_models/big-lama'\n",
    "\n",
    "lama_predictor, lama_predict_config = load_inpaint_model(LAMA_CONFIG, LAMA_CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint_img(image_array, mask):\n",
    "    img_inpainted = inpaint_img_with_model(img=image_array,\n",
    "                                           mask=mask,\n",
    "                                           model=lama_predictor,\n",
    "                                           predict_config=lama_predict_config)\n",
    "    return img_inpainted\n",
    "\n",
    "# img_path = '/root/rm_water_mark/imgs/image2_inpainted.jpg'\n",
    "# image = cv2.imread(img_path)\n",
    "# image_array = np.array(image)\n",
    "\n",
    "# combined_mask_array = np.array(combined_mask)\n",
    "img_clean_bg = inpaint_img(img_inpainted, combined_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv2.imwrite(pic_clean_bg_path, img_clean_bg)\n",
    "# img_inpainted_rgb = cv2.cvtColor(img_inpainted, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img_inpainted_rgb)\n",
    "# plt.axis('off')  # 不显示坐标轴\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将商品主体蒙版和无文字的干净背景融合，得到最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 原图\n",
    "# img_path = '/root/rm_water_mark/imgs/image2.jpg'\n",
    "# # 主体蒙版\n",
    "# mask_path = '/root/rm_water_mark/imgs/image2_mask.png'\n",
    "# # 背景图\n",
    "# bg_path = '/root/rm_water_mark/imgs/image2_bg.jpg'\n",
    "\n",
    "# img = cv2.imread(img_path)\n",
    "# mask = cv2.imread(mask_path)\n",
    "# bg = cv2.imread(bg_path)\n",
    "# 将img中mask以外的区域替换为bg中的内容\n",
    "result = original_image.copy()\n",
    "result[product_mask == 0] = img_clean_bg[product_mask == 0]\n",
    "\n",
    "cv2.imwrite(final_img_path, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost:  15.031396627426147\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print('Time cost: ', end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
